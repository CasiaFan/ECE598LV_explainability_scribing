@article{Vig2019AMV,
  title={A Multiscale Visualization of Attention in the Transformer Model},
  author={Jesse Vig},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.05714}
}
@article{Vig2019AMV,
  title={Explaining Artificial Intelligence Generation and Creativity: Human interpretability for novel ideas and artifacts},
  author={Payel Das and Lav R. Varshney},
  journal={IEEE SIGNAL PROCESSING MAGAZINE},
  year={2022},
  volume={1053-5888}
}
@article{Ahn2011FlavorNA,
  title={Flavor network and the principles of food pairing},
  author={Yong-Yeol Ahn and Sebastian E. Ahnert and James P. Bagrow and A L Barabasi},
  journal={Scientific Reports},
  year={2011},
  volume={1}
}
@article{Liu2004ConceptNetA,
  title={ConceptNet â€” A Practical Commonsense Reasoning Tool-Kit},
  author={Hugo Liu and Push Singh},
  journal={BT Technology Journal},
  year={2004},
  volume={22},
  pages={211-226}
}
@inproceedings{Mikolov2013DistributedRO,
  title={Distributed Representations of Words and Phrases and their Compositionality},
  author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
  booktitle={NIPS},
  year={2013}
}
@article{Mitchell2019ModelCF,
  title={Model Cards for Model Reporting},
  author={Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Gebru},
  journal={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  year={2019}
}
@article{Hind2019IncreasingTI,
  title={Increasing Trust in AI Services through Supplier's Declarations of Conformity},
  author={Michael Hind and Sameep Mehta and Aleksandra Mojsilovic and Ravindranath Gopinathan Nair and Karthikeyan Natesan Ramamurthy and Alexandra Olteanu and Kush R. Varshney},
  journal={IBM J. Res. Dev.},
  year={2019},
  volume={63},
  pages={6:1-6:13}
}
@article{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  journal={ArXiv},
  year={2019},
  volume={abs/1810.04805}
}
@article{Koroteev2021BERTAR,
  title={BERT: A Review of Applications in Natural Language Processing and Understanding},
  author={M. V. Koroteev},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.11943}
}
@article{Rogers2020API,
  title={A Primer in BERTology: What We Know About How BERT Works},
  author={Anna Rogers and Olga Kovaleva and Anna Rumshisky},
  journal={Transactions of the Association for Computational Linguistics},
  year={2020},
  volume={8},
  pages={842-866}
}
@misc{
yu2021information,
title={Information Lattice Learning},
author={Haizi Yu and James Evans and Lav R. Varshney},
year={2021},
url={https://openreview.net/forum?id=SzjyTIc5qMP}
}
@article{Rudin2019StopEB,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Cynthia Rudin},
  journal={Nature Machine Intelligence},
  year={2019},
  volume={1},
  pages={206-215}
}
@article{Jiang2020ConvBERTIB,
  title={ConvBERT: Improving BERT with Span-based Dynamic Convolution},
  author={Zihang Jiang and Weihao Yu and Daquan Zhou and Yunpeng Chen and Jiashi Feng and Shuicheng Yan},
  journal={ArXiv},
  year={2020},
  volume={abs/2008.02496}
}
@article{Kou2021ImprovingBW,
  title={Improving BERT With Self-Supervised Attention},
  author={Xiaoyu Kou and Yaming Yang and Yujing Wang and Ce Zhang and Yiren Chen and Yunhai Tong and Yan Zhang and Jing Bai},
  journal={IEEE Access},
  year={2021},
  volume={9},
  pages={144129-144139}
}
